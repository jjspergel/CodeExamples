{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyproj as proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_exc(ser, q):\n",
    "    ser_sorted = ser.squeeze().sort_values()\n",
    "    rank = q * (len(ser) + 1) - 1\n",
    "    assert rank > 0, 'quantile is too small'\n",
    "    rank_l = int(rank)\n",
    "    return ser_sorted.iat[rank_l] + (ser_sorted.iat[rank_l + 1] - \n",
    "                                     ser_sorted.iat[rank_l]) * (rank - rank_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('7Q10/turkeyhill_locationmetadata.txt',delimiter='\\t',header=59)\n",
    "metadata = metadata.drop(0)\n",
    "\n",
    "ddata = pd.read_csv('7Q10/discharge_turkeycreek.txt',delimiter='\\t',header=29,names=\n",
    "                   ['agency_code',\n",
    "                   'site_no',\n",
    "                   'date',\n",
    "                   'discharge_cfs',\n",
    "                   'approval'],parse_dates=[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot transform naive geometries.  Please set a crs on the object first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fec1b823fc14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwatershed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'7Q10/globalwatershed.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstatewide_lambert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_proj4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+proj=lcc +lat_0=0 +lon_0=-83.5 +lat_1=31.4166666666667 +lat_2=34.2833333333333 +x_0=0 +y_0=0 +datum=NAD83 +units=us-ft +no_defs +type=crs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwatershed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwatershed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatewide_lambert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mupstream_watershed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'7Q10/upstream_globalwatershed.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mto_crs\u001b[0;34m(self, crs, epsg, inplace)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0mgeom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/geoseries.py\u001b[0m in \u001b[0;36mto_crs\u001b[0;34m(self, crs, epsg)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \"\"\"\n\u001b[1;32m   1116\u001b[0m         return GeoSeries(\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         )\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/array.py\u001b[0m in \u001b[0;36mto_crs\u001b[0;34m(self, crs, epsg)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    751\u001b[0m                 \u001b[0;34m\"Cannot transform naive geometries.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;34m\"Please set a crs on the object first.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot transform naive geometries.  Please set a crs on the object first."
     ]
    }
   ],
   "source": [
    "#import requested watershed shapefile delineated from StreamStats\n",
    "watershed = gpd.read_file('7Q10/globalwatershed.shp')\n",
    "statewide_lambert = proj.CRS.from_proj4('+proj=lcc +lat_0=0 +lon_0=-83.5 +lat_1=31.4166666666667 +lat_2=34.2833333333333 +x_0=0 +y_0=0 +datum=NAD83 +units=us-ft +no_defs +type=crs')\n",
    "watershed = watershed.to_crs(statewide_lambert)\n",
    "\n",
    "upstream_watershed = gpd.read_file('7Q10/upstream_globalwatershed.shp')\n",
    "upstream_watershed = upstream_watershed.to_crs(statewide_lambert)\n",
    "\n",
    "basin_area = metadata.contrib_drain_area_va\n",
    "withdrawal_area = watershed.area * 3.587E-8 #convert from sq ft to sq miles\n",
    "upstream_area = upstream_watershed.area* 3.587E-8 #sq mi\n",
    "diff_in_area = withdrawal_area-upstream_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upstream demands of irrigated area, from external document\n",
    "irrigated_area = 215\n",
    "max_reservoir_volume = 28.224 #cubic feet\n",
    "pumprate = 1400 * 60 * 24 * 1.547/1e6 #gpm, converted to cfs (min/hr * hr/day * 1.547 cfs*day^-1/1e6 gallons*day^-1/)\n",
    "annual_demand = 15 * 250 /12 #af \n",
    "\n",
    "upstream_demands = pd.Series( #standardized inch/yr*acre demands (total15 in/yr), multiplied by acres irrigated area, converted to cfs\n",
    "[0.227,\n",
    "0.339,\n",
    "0.603,\n",
    "0.795,\n",
    "1.82,\n",
    "2.269,\n",
    "2.273,\n",
    "2.717,\n",
    "1.564,\n",
    "1.349,\n",
    "0.685,\n",
    "0.36]).multiply(irrigated_area)\n",
    "month_range = pd.date_range(start='01-01-2021',end='01-01-2022', freq='M')\n",
    "inches_in_feet = 12\n",
    "ftsq_in_acre = 43560\n",
    "seconds_in_day = 24*60*60\n",
    "#convert to cfs\n",
    "upstream_demands = upstream_demands.multiply(ftsq_in_acre).divide(inches_in_feet).divide(month_range.days_in_month).divide(seconds_in_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaporative Loss\n",
    "reservoir_surface_area = 7#acres\n",
    "evaporation_rate = pd.read_csv('RE__7Q10_Model/acfbasin_evapnetrate.csv',header=6,parse_dates=True,usecols=[1,2],names=['date','rate'])\n",
    "#multiply by reservoir area, convert to cfs\n",
    "evaporative_loss = pd.Series(data = \n",
    "                             evaporation_rate.rate.values*reservoir_surface_area*1/inches_in_feet*ftsq_in_acre*1/seconds_in_day,\n",
    "                             index = evaporation_rate.date.astype(np.datetime64))\n",
    "\n",
    "dummy = pd.Series(np.zeros(ddata.shape[0]),ddata.date)\n",
    "evaporative_loss = pd.Series.combine(evaporative_loss,dummy, max,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled by upstream drainage area of withdrawal site, divided by river catchment area\n",
    "ddata['scaled_by_area']=(ddata.discharge_cfs*(np.float(upstream_area)/np.float(basin_area)))\n",
    "#scaled by area difference btw upstream and downstream drainage areas of withdrawal site, divided by river catchment area\n",
    "ddata['scaled_by_diff']=(ddata.discharge_cfs*(np.float(diff_in_area)/np.float(basin_area)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdrawal = np.zeros([len(ddata.scaled_by_diff),1])\n",
    "for i in np.arange(0,withdrawal.shape[0]):\n",
    "    month = ddata.date[i].month\n",
    "    withdrawal[i] = max(ddata.scaled_by_area.values[i]-upstream_demands[month-1],0)\n",
    "    #timeseries of discharge = max(0,withdrawal)+scaled discharge\n",
    "inflow_data = np.add(ddata.scaled_by_diff.values,np.transpose(withdrawal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow_ts = pd.Series(data = inflow_data.squeeze(),index = ddata.date) #data used for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow_ts=inflow_ts[:np.argmin(ddata.date.le(dt.datetime(2022,6,30)))]\n",
    "inflow_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving 7 day Avg - translated from Excel \n",
    "nmonth = np.zeros([12,1],dtype=int)\n",
    "days7Ave = np.zeros([len(inflow_ts),1])\n",
    "\n",
    "for j in np.arange(0,11):\n",
    "    nmonth[j] = 0\n",
    "    \n",
    "    j=0\n",
    "    for i in np.arange(0, len(inflow_ts)-1):\n",
    "        j = j+1\n",
    "        if j < 6:\n",
    "            vsum=0\n",
    "            for k in np.arange(j,1,-1):\n",
    "                vsum = vsum + inflow_ts.values[k]\n",
    "            \n",
    "            days7Ave[j] = vsum/j\n",
    "        else:\n",
    "            vsum = 0\n",
    "            for k in np.arange(j, j-6, -1):\n",
    "                vsum = vsum + inflow_ts.values[k-1]\n",
    "            days7Ave[j-1] = vsum/7\n",
    "            \n",
    "    \n",
    "\n",
    "# Monthly minimum - translated from Excel\n",
    "mm7dayAve = np.zeros([12, len(np.unique(inflow_ts.index.year)), 2])\n",
    "tmm7dave = days7Ave[0]\n",
    "\n",
    "for k in np.arange(0, len(inflow_ts)-1):\n",
    "    if inflow_ts.index[k].month == inflow_ts.index[k-1].month:\n",
    "        if days7Ave[k] < tmm7dave:\n",
    "            tmm7dave = days7Ave[k]\n",
    "    else:\n",
    "        j = inflow_ts.index[k].month\n",
    "        nmonth[j-1] = nmonth[j-1]+1\n",
    "        mm7dayAve[j-1,nmonth[j-1],0] = tmm7dave\n",
    "        mm7dayAve[j-1,nmonth[j-1],1] = inflow_ts.index[k].toordinal()\n",
    "        tmm7dave  = days7Ave[k-1]\n",
    "    #end-of-record\n",
    "    if k==len(inflow_ts)-1:\n",
    "        j = inflow_ts.index[k].month\n",
    "        nmonth[j-1] = nmonth[j-1]\n",
    "        mm7dayAve[j-1,nmonth[j-1],0] = tmm7dave\n",
    "        mm7dayAve[j-1,nmonth[j-1],1] = inflow_ts.index[k].toordinal()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10=np.zeros([12,1])\n",
    "for m in np.arange(0,12):\n",
    "    mm7dayAve2 = np.zeros([int(nmonth[m]),1])\n",
    "      \n",
    "    for j in np.arange(0, nmonth[m]):\n",
    "        mm7dayAve2[j] = mm7dayAve[m, j, 0]\n",
    "        \n",
    "    \n",
    "    M7Q10[m] = quantile_exc(pd.Series(mm7dayAve2[1:].squeeze()),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.fromordinal(mm7dayAve[0,1,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pythonic\n",
    "weekly_inflow_ts = inflow_ts.rolling(7,center=True).mean()#weekly resample by median\n",
    "\n",
    "monthly_min_inflow_ts = weekly_inflow_ts.resample('1M').min() #monthly min of 7-day averages\n",
    "annual_min_inflow_ts = weekly_inflow_ts.resample('1Y').min() #annual min of 7-day averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_min_inflow_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10th percentile by month\n",
    "M7Q10 = monthly_min_inflow_ts.groupby(monthly_min_inflow_ts.index.month).aggregate(quantile_exc,q=0.1) \n",
    "#number of months included in calculation\n",
    "nmonths = monthly_min_inflow_ts.groupby(monthly_min_inflow_ts.index.month).aggregate(np.count_nonzero) \n",
    "\n",
    "#10th percentile by year\n",
    "A7Q10 = quantile_exc(annual_min_inflow_ts,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A7Q10.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10_flow = pd.Series(np.zeros(inflow_ts.shape),inflow_ts.index) #MIF, flow timeseries where each day's flow = monthly M7Q10 \n",
    "for month in np.arange(1,12):\n",
    "    M7Q10_flow[M7Q10_flow.index.month == month] = M7Q10[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when inflow < M7Q10, then in-stream outflow = inflow, otherwise outflow = M7Q10\n",
    "instream_flow = M7Q10_flow \n",
    "instream_flow[inflow_ts<=M7Q10_flow] = inflow_ts\n",
    "instream_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_flow = inflow_ts-instream_flow\n",
    "available_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pump_demand = pd.Series(data = np.zeros(inflow_ts.shape[0]), index=inflow_ts.index)\n",
    "\n",
    "pump_demand[np.bitwise_or(pump_demand.index.month>=4 , pump_demand.index.month<=9)] = pumprate\n",
    "pump_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time Varying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_water_vol = np.zeros([inflow_ts.shape[0]+1,1]) #s1\n",
    "endofday_stored_water = np.zeros([inflow_ts.shape[0]+1,1]) #storage\n",
    "pumped_water = np.zeros([inflow_ts.shape[0]+1,1]) #pumped\n",
    "left_in_stream = np.zeros([inflow_ts.shape[0]+1,1]) #remaining, what stream water is left after pumping \n",
    "pump_gap  = np.zeros([inflow_ts.shape[0]+1,1])  #gap between pump demand and what is pumped\n",
    "\n",
    "endofday_stored_water[0] = max_reservoir_volume\n",
    "#available_water_vol[0] = inflow_ts[0]+max_reservoir_volume - instream_flow[0] - evaporative_loss[0]\n",
    "#pumped_water[0] = max(min(available_water_vol[0],pump_demand[0]),0)\n",
    "#left_in_stream[0] = instream_flow[0]  + max(available_water_vol[0]-pumped_water[0]-max_reservoir_volume,0)\n",
    "#pump_gap[0] = pump_demand[0]-pumped_water[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(1, inflow_ts.shape[0]-1):\n",
    "    available_water_vol[t] = inflow_ts.values[t-1]+endofday_stored_water[t-1] - instream_flow.values[t-1] - evaporative_loss.values[t-1]\n",
    "    pumped_water[t] = max(min(available_water_vol[t],pump_demand.values[t-1]),0)\n",
    "    left_in_stream[t] = instream_flow.values[t-1]  + max(available_water_vol[t]-pumped_water[t]-max_reservoir_volume,0)\n",
    "    pump_gap[t] = pump_demand[t]-pumped_water[t]\n",
    "    endofday_stored_water[t] = max(min(available_water_vol[t]-pumped_water[t],max_reservoir_volume),0)\n",
    "\n",
    "available_water_vol = available_water_vol[1:]\n",
    "endofday_stored_water = endofday_stored_water[1:]\n",
    "pumped_water = pumped_water[1:]\n",
    "left_in_stream = left_in_stream[1:]\n",
    "pump_gap  = pump_gap[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumped_water_ts = pd.Series(data=pumped_water.squeeze(), index = inflow_ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pumped_water_ts*3.06888785).groupby(pumped_water_ts.index.year).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
