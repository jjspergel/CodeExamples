{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyproj as proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_exc(ser, q):\n",
    "    ser_sorted = ser.squeeze().sort_values()\n",
    "    rank = q * (len(ser) + 1) - 1\n",
    "    assert rank > 0, 'quantile is too small'\n",
    "    rank_l = int(rank)\n",
    "    return ser_sorted.iat[rank_l] + (ser_sorted.iat[rank_l + 1] - \n",
    "                                     ser_sorted.iat[rank_l]) * (rank - rank_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('turkeyhill_locationmetadata.txt',delimiter='\\t',header=59)\n",
    "metadata = metadata.drop(0)\n",
    "\n",
    "ddata = pd.read_csv('discharge_turkeycreek.txt',delimiter='\\t',header=29,names=\n",
    "                   ['agency_code',\n",
    "                   'site_no',\n",
    "                   'date',\n",
    "                   'discharge_cfs',\n",
    "                   'approval'],parse_dates=[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requested watershed shapefile delineated from StreamStats\n",
    "watershed = gpd.read_file('globalwatershed.shp')\n",
    "statewide_lambert = proj.CRS.from_proj4('+proj=lcc +lat_0=0 +lon_0=-83.5 +lat_1=31.4166666666667 +lat_2=34.2833333333333 +x_0=0 +y_0=0 +datum=NAD83 +units=us-ft +no_defs +type=crs')\n",
    "watershed = watershed.to_crs(statewide_lambert)\n",
    "\n",
    "upstream_watershed = gpd.read_file('upstream_globalwatershed.shp')\n",
    "upstream_watershed = upstream_watershed.to_crs(statewide_lambert)\n",
    "\n",
    "basin_area = metadata.contrib_drain_area_va\n",
    "withdrawal_area = watershed.area * 3.587E-8 #convert from sq ft to sq miles\n",
    "upstream_area = upstream_watershed.area* 3.587E-8 #sq mi\n",
    "diff_in_area = withdrawal_area-upstream_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upstream demands of irrigated area, from external document\n",
    "irrigated_area = 215\n",
    "max_reservoir_volume = 28.224 #cubic feet\n",
    "pumprate = 1400 * 60 * 24 * 1.547/1e6 #gpm, converted to cfs (min/hr * hr/day * 1.547 cfs*day^-1/1e6 gallons*day^-1/)\n",
    "annual_demand = 15 * 250 /12 #af \n",
    "\n",
    "upstream_demands = pd.Series( #standardized inch/yr*acre demands (total15 in/yr), multiplied by acres irrigated area, converted to cfs\n",
    "[0.227,\n",
    "0.339,\n",
    "0.603,\n",
    "0.795,\n",
    "1.82,\n",
    "2.269,\n",
    "2.273,\n",
    "2.717,\n",
    "1.564,\n",
    "1.349,\n",
    "0.685,\n",
    "0.36]).multiply(irrigated_area)\n",
    "month_range = pd.date_range(start='01-01-2021',end='01-01-2022', freq='M')\n",
    "inches_in_feet = 12\n",
    "ftsq_in_acre = 43560\n",
    "seconds_in_day = 24*60*60\n",
    "#convert to cfs\n",
    "upstream_demands = upstream_demands.multiply(ftsq_in_acre).divide(inches_in_feet).divide(month_range.days_in_month).divide(seconds_in_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaporative Loss\n",
    "reservoir_surface_area = 7#acres\n",
    "evaporation_rate = pd.read_csv('acfbasin_evapnetrate.csv',header=6,parse_dates=True,usecols=[1,2],names=['date','rate'])\n",
    "#multiply by reservoir area, convert to cfs\n",
    "evaporative_loss = pd.Series(data = \n",
    "                             evaporation_rate.rate.values*reservoir_surface_area*1/inches_in_feet*ftsq_in_acre*1/seconds_in_day,\n",
    "                             index = evaporation_rate.date.astype(np.datetime64))\n",
    "\n",
    "dummy = pd.Series(np.zeros(ddata.shape[0]),ddata.date)\n",
    "evaporative_loss = pd.Series.combine(evaporative_loss,dummy, max,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled by upstream drainage area of withdrawal site, divided by river catchment area\n",
    "ddata['scaled_by_area']=(ddata.discharge_cfs*(np.float(upstream_area)/np.float(basin_area)))\n",
    "#scaled by area difference btw upstream and downstream drainage areas of withdrawal site, divided by river catchment area\n",
    "ddata['scaled_by_diff']=(ddata.discharge_cfs*(np.float(diff_in_area)/np.float(basin_area)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdrawal = np.zeros([len(ddata.scaled_by_diff),1])\n",
    "for i in np.arange(0,withdrawal.shape[0]):\n",
    "    month = ddata.date[i].month\n",
    "    withdrawal[i] = max(ddata.scaled_by_area.values[i]-upstream_demands[month-1],0)\n",
    "    #timeseries of discharge = max(0,withdrawal)+scaled discharge\n",
    "inflow_data = np.add(ddata.scaled_by_diff.values,np.transpose(withdrawal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow_ts = pd.Series(data = inflow_data.squeeze(),index = ddata.date) #data used for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958-06-20    0.140436\n",
       "1958-06-21    0.166767\n",
       "1958-06-22    0.105327\n",
       "1958-06-23    0.087772\n",
       "1958-06-24    0.083384\n",
       "                ...   \n",
       "2022-06-26    0.019090\n",
       "2022-06-27    0.018169\n",
       "2022-06-28    0.017818\n",
       "2022-06-29    0.035592\n",
       "2022-06-30    0.027166\n",
       "Length: 23387, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflow_ts=inflow_ts[:np.argmin(ddata.date.le(dt.datetime(2022,6,30)))]\n",
    "inflow_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving 7 day Avg - translated from Excel \n",
    "nmonth = np.zeros([12,1],dtype=int)\n",
    "days7Ave = np.zeros([len(inflow_ts),1])\n",
    "\n",
    "for j in np.arange(0,11):\n",
    "    nmonth[j] = 0\n",
    "    \n",
    "    j=0\n",
    "    for i in np.arange(0, len(inflow_ts)-1):\n",
    "        j = j+1\n",
    "        if j < 6:\n",
    "            vsum=0\n",
    "            for k in np.arange(j,1,-1):\n",
    "                vsum = vsum + inflow_ts.values[k]\n",
    "            \n",
    "            days7Ave[j] = vsum/j\n",
    "        else:\n",
    "            vsum = 0\n",
    "            for k in np.arange(j, j-6, -1):\n",
    "                vsum = vsum + inflow_ts.values[k-1]\n",
    "            days7Ave[j-1] = vsum/7\n",
    "            \n",
    "    \n",
    "\n",
    "# Monthly minimum - translated from Excel\n",
    "mm7dayAve = np.zeros([12, len(np.unique(inflow_ts.index.year)), 2])\n",
    "tmm7dave = days7Ave[0]\n",
    "\n",
    "for k in np.arange(0, len(inflow_ts)-1):\n",
    "    if inflow_ts.index[k].month == inflow_ts.index[k-1].month:\n",
    "        if days7Ave[k] < tmm7dave:\n",
    "            tmm7dave = days7Ave[k]\n",
    "    else:\n",
    "        j = inflow_ts.index[k].month\n",
    "        nmonth[j-1] = nmonth[j-1]+1\n",
    "        mm7dayAve[j-1,nmonth[j-1],0] = tmm7dave\n",
    "        mm7dayAve[j-1,nmonth[j-1],1] = inflow_ts.index[k].toordinal()\n",
    "        tmm7dave  = days7Ave[k-1]\n",
    "    #end-of-record\n",
    "    if k==len(inflow_ts)-1:\n",
    "        j = inflow_ts.index[k].month\n",
    "        nmonth[j-1] = nmonth[j-1]\n",
    "        mm7dayAve[j-1,nmonth[j-1],0] = tmm7dave\n",
    "        mm7dayAve[j-1,nmonth[j-1],1] = inflow_ts.index[k].toordinal()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64],\n",
       "       [64]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10=np.zeros([12,1])\n",
    "for m in np.arange(0,12):\n",
    "    mm7dayAve2 = np.zeros([int(nmonth[m]),1])\n",
    "      \n",
    "    for j in np.arange(0, nmonth[m]):\n",
    "        mm7dayAve2[j] = mm7dayAve[m, j, 0]\n",
    "        \n",
    "    \n",
    "    M7Q10[m] = quantile_exc(pd.Series(mm7dayAve2[1:].squeeze()),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01551188],\n",
       "       [0.02371427],\n",
       "       [0.03799579],\n",
       "       [0.05852939],\n",
       "       [0.02793668],\n",
       "       [0.01445987],\n",
       "       [0.01122232],\n",
       "       [0.00957596],\n",
       "       [0.00870325],\n",
       "       [0.0087835 ],\n",
       "       [0.00837724],\n",
       "       [0.01189942]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M7Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1959-01-01 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp.fromordinal(mm7dayAve[0,1,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pythonic\n",
    "weekly_inflow_ts = inflow_ts.rolling(7,center=True).mean()#weekly resample by median\n",
    "\n",
    "monthly_min_inflow_ts = weekly_inflow_ts.resample('1M').min() #monthly min of 7-day averages\n",
    "annual_min_inflow_ts = weekly_inflow_ts.resample('1Y').min() #annual min of 7-day averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958-06-30    0.048212\n",
       "1958-07-31    0.036426\n",
       "1958-08-31    0.033479\n",
       "1958-09-30    0.024576\n",
       "1958-10-31    0.024012\n",
       "                ...   \n",
       "2022-02-28    0.244062\n",
       "2022-03-31    0.158367\n",
       "2022-04-30    0.093959\n",
       "2022-05-31    0.040808\n",
       "2022-06-30    0.019993\n",
       "Freq: M, Length: 769, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_min_inflow_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10th percentile by month\n",
    "M7Q10 = monthly_min_inflow_ts.groupby(monthly_min_inflow_ts.index.month).aggregate(quantile_exc,q=0.1) \n",
    "#number of months included in calculation\n",
    "nmonths = monthly_min_inflow_ts.groupby(monthly_min_inflow_ts.index.month).aggregate(np.count_nonzero) \n",
    "\n",
    "#10th percentile by year\n",
    "A7Q10 = quantile_exc(annual_min_inflow_ts,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1     0.032084\n",
       "2     0.054619\n",
       "3     0.068101\n",
       "4     0.030971\n",
       "5     0.016865\n",
       "6     0.013201\n",
       "7     0.011244\n",
       "8     0.010157\n",
       "9     0.010461\n",
       "10    0.010338\n",
       "11    0.015407\n",
       "12    0.018373\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M7Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A7Q10.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "M7Q10_flow = pd.Series(np.zeros(inflow_ts.shape),inflow_ts.index) #MIF, flow timeseries where each day's flow = monthly M7Q10 \n",
    "for month in np.arange(1,12):\n",
    "    M7Q10_flow[M7Q10_flow.index.month == month] = M7Q10[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958-06-20    0.013201\n",
       "1958-06-21    0.013201\n",
       "1958-06-22    0.013201\n",
       "1958-06-23    0.013201\n",
       "1958-06-24    0.013201\n",
       "                ...   \n",
       "2022-06-26    0.013201\n",
       "2022-06-27    0.013201\n",
       "2022-06-28    0.013201\n",
       "2022-06-29    0.013201\n",
       "2022-06-30    0.013201\n",
       "Length: 23387, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when inflow < M7Q10, then in-stream outflow = inflow, otherwise outflow = M7Q10\n",
    "instream_flow = M7Q10_flow \n",
    "instream_flow[inflow_ts<=M7Q10_flow] = inflow_ts\n",
    "instream_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958-06-20    0.127235\n",
       "1958-06-21    0.153566\n",
       "1958-06-22    0.092126\n",
       "1958-06-23    0.074571\n",
       "1958-06-24    0.070183\n",
       "                ...   \n",
       "2022-06-26    0.005890\n",
       "2022-06-27    0.004968\n",
       "2022-06-28    0.004617\n",
       "2022-06-29    0.022391\n",
       "2022-06-30    0.013965\n",
       "Length: 23387, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_flow = inflow_ts-instream_flow\n",
    "available_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958-06-20    3.118752\n",
       "1958-06-21    3.118752\n",
       "1958-06-22    3.118752\n",
       "1958-06-23    3.118752\n",
       "1958-06-24    3.118752\n",
       "                ...   \n",
       "2022-06-26    3.118752\n",
       "2022-06-27    3.118752\n",
       "2022-06-28    3.118752\n",
       "2022-06-29    3.118752\n",
       "2022-06-30    3.118752\n",
       "Length: 23387, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pump_demand = pd.Series(data = np.zeros(inflow_ts.shape[0]), index=inflow_ts.index)\n",
    "\n",
    "pump_demand[np.bitwise_or(pump_demand.index.month>=4 , pump_demand.index.month<=9)] = pumprate\n",
    "pump_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time Varying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_water_vol = np.zeros([inflow_ts.shape[0]+1,1]) #s1\n",
    "endofday_stored_water = np.zeros([inflow_ts.shape[0]+1,1]) #storage\n",
    "pumped_water = np.zeros([inflow_ts.shape[0]+1,1]) #pumped\n",
    "left_in_stream = np.zeros([inflow_ts.shape[0]+1,1]) #remaining, what stream water is left after pumping \n",
    "pump_gap  = np.zeros([inflow_ts.shape[0]+1,1])  #gap between pump demand and what is pumped\n",
    "\n",
    "endofday_stored_water[0] = max_reservoir_volume\n",
    "#available_water_vol[0] = inflow_ts[0]+max_reservoir_volume - instream_flow[0] - evaporative_loss[0]\n",
    "#pumped_water[0] = max(min(available_water_vol[0],pump_demand[0]),0)\n",
    "#left_in_stream[0] = instream_flow[0]  + max(available_water_vol[0]-pumped_water[0]-max_reservoir_volume,0)\n",
    "#pump_gap[0] = pump_demand[0]-pumped_water[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(1, inflow_ts.shape[0]-1):\n",
    "    available_water_vol[t] = inflow_ts.values[t-1]+endofday_stored_water[t-1] - instream_flow.values[t-1] - evaporative_loss.values[t-1]\n",
    "    pumped_water[t] = max(min(available_water_vol[t],pump_demand.values[t-1]),0)\n",
    "    left_in_stream[t] = instream_flow.values[t-1]  + max(available_water_vol[t]-pumped_water[t]-max_reservoir_volume,0)\n",
    "    pump_gap[t] = pump_demand[t]-pumped_water[t]\n",
    "    endofday_stored_water[t] = max(min(available_water_vol[t]-pumped_water[t],max_reservoir_volume),0)\n",
    "\n",
    "available_water_vol = available_water_vol[1:]\n",
    "endofday_stored_water = endofday_stored_water[1:]\n",
    "pumped_water = pumped_water[1:]\n",
    "left_in_stream = left_in_stream[1:]\n",
    "pump_gap  = pump_gap[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumped_water_ts = pd.Series(data=pumped_water.squeeze(), index = inflow_ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1958    118.675370\n",
       "1959    569.841500\n",
       "1960    556.917662\n",
       "1961    317.958336\n",
       "1962    556.800379\n",
       "           ...    \n",
       "2018    415.184716\n",
       "2019    458.232247\n",
       "2020    794.040696\n",
       "2021    614.637972\n",
       "2022    266.091688\n",
       "Length: 65, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pumped_water_ts*3.06888785).groupby(pumped_water_ts.index.year).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
